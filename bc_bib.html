<h1>bc.bib</h1><a name="M09c"></a><pre>
@incollection{<a href="bc.html#M09c">M09c</a>,
  author = {I. Markovsky},
  editor = {A. Iske and E. Georgoulis and J. Levesley},
  title = {Algorithms and literate programs for weighted low-rank approximation with missing data},
  publisher = {Springer},
  year = {2011},
  volume = {3},
  chapter = {12},
  series = {Springer Proc. in Mathematics},
  pages = {255--273},
  pdf = {<a href="http://eprints.soton.ac.uk/268296/2/missing-data-2x1.pdf">http://eprints.soton.ac.uk/268296/2/missing-data-2x1.pdf</a>},
  software = {<a href="http://eprints.soton.ac.uk/268296/7/missing-data.tar">http://eprints.soton.ac.uk/268296/7/missing-data.tar</a>},
  doi = {10.1007/978-3-642-16876-5_12}
}
</pre>

<a name="dist-chapter"></a><pre>
@incollection{<a href="bc.html#dist-chapter">dist-chapter</a>,
  author = {I. Markovsky},
  title = {Rank constrained optimization problems in computer vision},
  booktitle = {Regularization, Optimization, Kernels, and Support Vector Machines},
  publisher = {Chapman \& Hall/CRC Machine Learning},
  year = {2014},
  editor = {J. Suykens, M. Signoretto, A. Argyriou},
  series = {Pattern Recognition},
  optchapter = {},
  optpages = {},
  pdf = {<a href="http://homepages.vub.ac.be/~imarkovs/publications/dist-chapter.pdf">http://homepages.vub.ac.be/~imarkovs/publications/dist-chapter.pdf</a>},
  isbn = {9781482241396}
}
</pre>

<a name="kpca"></a><pre>
@incollection{<a href="bc.html#kpca">kpca</a>,
  author = {I. Markovsky and K. Usevich},
  title = {Nonlinearly structured low-rank approximation},
  booktitle = {Low-Rank and Sparse Modeling for Visual Analysis},
  publisher = {Springer},
  year = {2014},
  editor = {Yun Raymond Fu},
  optchapter = {},
  optpages = {},
  pdf = {<a href="http://homepages.vub.ac.be/~imarkovs/publications/kpca.pdf">http://homepages.vub.ac.be/~imarkovs/publications/kpca.pdf</a>},
  optdoi = {},
  abstract = {Polynomially structured low-rank approximation problems occur in algebraic curve fitting, \eg, conic section fitting, subspace clustering (generalized principal component analysis), and nonlinear and parameter-varying system identification. The maximum likelihood estimation principle applied to these nonlinear models leads to nonconvex optimization problems and yields inconsistent estimators in the errors-in-variables (measurement errors) setting.
We propose a computationally cheap and statistically consistent estimator based on a bias correction procedure, called adjusted least-squares estimation. The method is successfully used for conic section fitting and was recently generalized to algebraic curve fitting. The contribution of this book's chapter is the application of the polynomially structured low-rank approximation problem and, in particular, the adjusted least-squares method to subspace clustering, nonlinear and parameter-varying system identification. The classical in system identification input-output notion of a dynamical model is replaced by the behavioral definition of a model as a set, represented by implicit nonlinear difference equations.},
  keywords = {structured low-rank approximation, conic section fitting, subspace clustering, nonlinear system identification.}
}
</pre>

<hr><p><em>This file was generated by
<a href="http://www.lri.fr/~filliatr/bibtex2html/">bibtex2html</a> 1.97.</em></p>
