
<table>

<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="ident-prague">1</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky.
 System identification in the behavioral setting: A structured
  low-rank approximation approach.
 In E.&nbsp;Vincent et&nbsp;al., editors, <em>Latent Variable Analysis and
  Signal Separation</em>, volume 9237 of <em>Lecture Notes in Computer Science</em>.
  Springer, 2015.
[&nbsp;<a href="bc_bib.html#ident-prague">bib</a>&nbsp;| 
<a href="http://homepages.vub.ac.be/~imarkovs/publications/ident-prague-2x1.pdf">pdf</a>&nbsp;]
<blockquote>
System identification is a fast growing research area that encompasses a broad range of problems and solution methods. It is desirable to have a unifying setting and a few common principles that are sufficient to understand the currently existing identification methods. The behavioral approach to system and control, put forward in the mid 80's, is such a unifying setting. Till recently, however, the behavioral approach lacked supporting numerical solution methods. In the last 10 yeas, the structured low-rank approximation setting was used to fulfill this gap. In this paper, we summarize recent progress on methods for system identification in the behavioral setting and pose some open problems. First, we show that errors-in-variables and output error system identification problems are equivalent to Hankel structured low-rank approximation. Then, we outline three generic solution approaches: 1) methods based on local optimization, 2) methods based on convex relaxations, and 3) subspace methods. A specific example of a subspace identification method-data-driven impulse response computation-is presented in full details. In order to achieve the desired unification, the classical ARMAX identification problem should also be formulated as a structured low-rank approximation problem. This is an outstanding open problem.
</blockquote>
<p><blockquote>
Keywords: system identification; errors-in-variables modeling, behavioral approach; Hankel matrix, low-rank approximation, impulse response estimation, ARMAX identification.
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="dist-chapter">2</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky.
 Rank constrained optimization problems in computer vision.
 In A.&nbsp;Argyriou J.&nbsp;Suykens, M.&nbsp;Signoretto, editor, <em>
  Regularization, Optimization, Kernels, and Support Vector Machines</em>, Pattern
  Recognition, chapter&nbsp;13, pages 293-312. Chapman &amp; Hall/CRC Machine
  Learning, 2014.
[&nbsp;<a href="bc_bib.html#dist-chapter">bib</a>&nbsp;| 
<a href="http://homepages.vub.ac.be/~imarkovs/publications/dist-chapter.pdf">pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="kpca">3</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky and K.&nbsp;Usevich.
 Nonlinearly structured low-rank approximation.
 In Yun&nbsp;Raymond Fu, editor, <em>Low-Rank and Sparse Modeling for
  Visual Analysis</em>, pages 1-22. Springer, 2014.
[&nbsp;<a href="bc_bib.html#kpca">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1007/978-3-319-12000-3_1">DOI</a>&nbsp;| 
<a href="http://homepages.vub.ac.be/~imarkovs/publications/kpca.pdf">pdf</a>&nbsp;]
<blockquote>
Polynomially structured low-rank approximation problems occur in algebraic curve fitting, , conic section fitting, subspace clustering (generalized principal component analysis), and nonlinear and parameter-varying system identification. The maximum likelihood estimation principle applied to these nonlinear models leads to nonconvex optimization problems and yields inconsistent estimators in the errors-in-variables (measurement errors) setting.
We propose a computationally cheap and statistically consistent estimator based on a bias correction procedure, called adjusted least-squares estimation. The method is successfully used for conic section fitting and was recently generalized to algebraic curve fitting. The contribution of this book's chapter is the application of the polynomially structured low-rank approximation problem and, in particular, the adjusted least-squares method to subspace clustering, nonlinear and parameter-varying system identification. The classical in system identification input-output notion of a dynamical model is replaced by the behavioral definition of a model as a set, represented by implicit nonlinear difference equations.
</blockquote>
<p><blockquote>
Keywords: structured low-rank approximation, conic section fitting, subspace clustering, nonlinear system identification.
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="M09c">4</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky.
 Algorithms and literate programs for weighted low-rank approximation
  with missing data.
 volume&nbsp;3 of <em>Springer Proc. in Mathematics</em>, chapter&nbsp;12, pages
  255-273. Springer, 2011.
[&nbsp;<a href="bc_bib.html#M09c">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1007/978-3-642-16876-5_12">DOI</a>&nbsp;| 
<a href="http://eprints.soton.ac.uk/268296/2/missing-data-2x1.pdf">pdf</a>&nbsp;| 
<a href="http://eprints.soton.ac.uk/268296/7/missing-data.tar">software</a>&nbsp;]

</td>
</tr>
</table><hr><p><em>This file was generated by
<a href="http://www.lri.fr/~filliatr/bibtex2html/">bibtex2html</a> 1.97.</em></p>
