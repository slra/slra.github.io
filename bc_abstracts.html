
<table>

<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="dist-chapter">1</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky.
 Rank constrained optimization problems in computer vision.
 In A.&nbsp;Argyriou J.&nbsp;Suykens, M.&nbsp;Signoretto, editor, <em>
  Regularization, Optimization, Kernels, and Support Vector Machines</em>, Pattern
  Recognition, chapter&nbsp;13, pages 293-312. Chapman &amp; Hall/CRC Machine
  Learning, 2014.
[&nbsp;<a href="bc_bib.html#dist-chapter">bib</a>&nbsp;| 
<a href="http://homepages.vub.ac.be/~imarkovs/publications/dist-chapter.pdf">pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="kpca">2</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky and K.&nbsp;Usevich.
 Nonlinearly structured low-rank approximation.
 In Yun&nbsp;Raymond Fu, editor, <em>Low-Rank and Sparse Modeling for
  Visual Analysis</em>, pages 1-22. Springer, 2014.
[&nbsp;<a href="bc_bib.html#kpca">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1007/978-3-319-12000-3_1">DOI</a>&nbsp;| 
<a href="http://homepages.vub.ac.be/~imarkovs/publications/kpca.pdf">pdf</a>&nbsp;]
<blockquote>
Polynomially structured low-rank approximation problems occur in algebraic curve fitting, , conic section fitting, subspace clustering (generalized principal component analysis), and nonlinear and parameter-varying system identification. The maximum likelihood estimation principle applied to these nonlinear models leads to nonconvex optimization problems and yields inconsistent estimators in the errors-in-variables (measurement errors) setting.
We propose a computationally cheap and statistically consistent estimator based on a bias correction procedure, called adjusted least-squares estimation. The method is successfully used for conic section fitting and was recently generalized to algebraic curve fitting. The contribution of this book's chapter is the application of the polynomially structured low-rank approximation problem and, in particular, the adjusted least-squares method to subspace clustering, nonlinear and parameter-varying system identification. The classical in system identification input-output notion of a dynamical model is replaced by the behavioral definition of a model as a set, represented by implicit nonlinear difference equations.
</blockquote>
<p><blockquote>
Keywords: structured low-rank approximation, conic section fitting, subspace clustering, nonlinear system identification.
</blockquote>

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="M09c">3</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Markovsky.
 Algorithms and literate programs for weighted low-rank approximation
  with missing data.
 volume&nbsp;3 of <em>Springer Proc. in Mathematics</em>, chapter&nbsp;12, pages
  255-273. Springer, 2011.
[&nbsp;<a href="bc_bib.html#M09c">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1007/978-3-642-16876-5_12">DOI</a>&nbsp;| 
<a href="http://eprints.soton.ac.uk/268296/2/missing-data-2x1.pdf">pdf</a>&nbsp;| 
<a href="http://eprints.soton.ac.uk/268296/7/missing-data.tar">software</a>&nbsp;]

</td>
</tr>
</table><hr><p><em>This file was generated by
<a href="http://www.lri.fr/~filliatr/bibtex2html/">bibtex2html</a> 1.97.</em></p>
