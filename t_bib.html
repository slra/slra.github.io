<h1>t.bib</h1><a name="my-nucnrm"></a><pre>
@techreport{<a href="t.html#my-nucnrm">my-nucnrm</a>,
  author = {I. Markovsky},
  title = {Data modeling using the nuclear norm heuristic},
  institution = {ECS, Univ. of Southampton},
  year = {2011},
  number = {21936},
  url = {<a href="http://eprints.ecs.soton.ac.uk/21936/">http://eprints.ecs.soton.ac.uk/21936/</a>}
}
</pre>

<a name="armax"></a><pre>
@techreport{<a href="t.html#armax">armax</a>,
  author = {I. Markovsky},
  title = {{ARMAX} identification by structured low-rank approximation},
  institution = {Vrije Univ. Brussel},
  year = {2013}
}
</pre>

<a name="slra-agcd"></a><pre>
@techreport{<a href="t.html#slra-agcd">slra-agcd</a>,
  author = {K. Usevich and I. Markovsky},
  title = {Variable projection methods for approximate (greatest) common divisor computations},
  year = {2013},
  institution = {Vrije Univ. Brussel},
  url = {<a href="http://arxiv.org/abs/1304.6962">http://arxiv.org/abs/1304.6962</a>},
  pdf = {<a href="http://arxiv.org/pdf/1304.6962v1">http://arxiv.org/pdf/1304.6962v1</a>},
  abstract = {We consider the problem of finding for a given $N$-tuple of polynomials the closest $N$-tuple that has a common divisor of degree at least $d$. Extended weighted Euclidean semi-norm of coefficients is used as a measure of closeness. Two equivalent formulations of the problem are considered: (i) direct optimization over common divisors and cofactors, and (ii) Sylvester lowrank approximation. We use the duality between least-squares and least-norm problems to show that (i) and (ii) are closely related to mosaic Hankel low-rank approximation. This allows us to apply recent results on complexity and accuracy of computations for mosaic Hankel low-rank approximation. We develop optimization methods based on the variable projection principle. These methods have linear complexity in the degrees of the polynomials if either $d$ is small or $d$ is of the same order as the degrees of the polynomials. We provide a software implementation that is based on a software package for structured low-rank approximation.}
}
</pre>

<a name="als-kdu"></a><pre>
@techreport{<a href="t.html#als-kdu">als-kdu</a>,
  author = {K. Usevich and I. Markovsky},
  title = {Adjusted least squares estimator for algebraic hypersurface fitting},
  year = {2014},
  institution = {Vrije Univ. Brussel},
  optpdf = {??},
  abstract = {We consider the problem of fitting a set of points in Euclidean space by an algebraic hypersurface. We assume that the points on a true hypersurface are corrupted by Gaussian noise, and we estimate the coefficients of the true polynomial equation. The adjusted least squares estimator accounts for the bias present in the ordinary least squares estimator. The adjusted least squares estimator is based on constructing a quasi-Hankel matrix, which is a bias-corrected matrix of moments. For the case of unknown noise variance, the estimator is defined as a solution of a polynomial eigenvalue problem. In this paper, we present new results on invariance properties of the adjusted least squares estimator and an improved algorithm for computing the estimator for an arbitrary set of monomials in the polynomial equation.}
}
</pre>

<a name="slra-consistency"></a><pre>
@techreport{<a href="t.html#slra-consistency">slra-consistency</a>,
  author = {I. Markovsky and R. Pintelon},
  title = {Identification of linear time-invariant systems from multiple experiments},
  year = {2014},
  institution = {Vrije Univ. Brussel},
  optpdf = {??},
  abstract = {A standard assumption for consistent estimation in the errors-in-variables setting is persistency of excitation of the noise free input signal. We relax this assumption by considering data from multiple experiments. Consistency is obtained asymptotically as the number of experiments tends to infinity. The main theoretical and algorithmic difficulties are related to the growing number of to-be-estimated initial conditions. The method proposed in the paper is based on analytic elimination of the initial conditions and optimization over the remaining parameters. The resulting estimator is consistent, however, achieving asymptotically efficiency remains an open problem.},
  keywords = {maximum likelihood system identification, sum-of-damped exponentials modeling, consistency, structured low-rank approximation}
}
</pre>

<a name="uncontr"></a><pre>
@techreport{<a href="t.html#uncontr">uncontr</a>,
  author = {N. Guglielmi and I. Markovsky},
  title = {Computing the distance to uncontrollability: the {SISO} case},
  year = {2014},
  institution = {Vrije Univ. Brussel},
  pdf = {<a href="http://homepages.vub.ac.be/~imarkovs/publications/uncontr.pdf">http://homepages.vub.ac.be/~imarkovs/publications/uncontr.pdf</a>},
  abstract = {In this paper, the problem of computing the distance from a given linear time-invariant system to the nearest uncontrollable system is posed and solved in the behavioral setting. In the case of a system with two external variables, the problem is restated as a Sylvester structured distance to singularity problem. The structured distance to singularity problem is then solved by integrating a system of ordinary differential equations which describes the gradient associated to the cost functional.
An advantage of the method with respect to other approaches is in its capability to include further constraints. Numerical simulations also show that the method is more robust to the initial approximation than the Newton-type methods.},
  keywords = {Sylvester matrix, structured pseudospectrum, structured low-rank approximation, ODEs on matrix manifolds, structured distance to singularity, distance to uncontrollability, behavioral approach.}
}
</pre>

<hr><p><em>This file was generated by
<a href="http://www.lri.fr/~filliatr/bibtex2html/">bibtex2html</a> 1.97.</em></p>
